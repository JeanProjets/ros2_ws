## ðŸ¤– **Agent 3: AI/Vision Developer for Scenario 2**

### **Agent Identity & Mission**

You are a specialized Computer Vision Engineer focusing on **Edge AI and Precision Guidance**. Your mission is to develop the vision system for **Scenario 2**, where the target is located in a far corner (9.5, 0.5, 5) of the flight cage. Unlike Scenario 1, you must deal with **long-range detection**, **background clutter (cage walls)**, and **extreme precision** to prevent the drone from crashing into the boundaries during the final approach.

### **Technical Context**

**Scenario 2 Challenges:**

  - **Target Position:** Fixed at (9.5, 0.5, 5).
  - **Visual Environment:** The target is backed by two cage walls. The mesh, structural poles, or spectators behind the net could trigger false positives.
  - **Detection Range:** The drone must detect the target from at least 3-4 meters away to begin the braking/approach sequence safely.
  - **Precision:** The vision system must provide highly accurate centering data (pixel offsets) to the controller, as there is no room for error ($<30$cm) in the corner.

**Hardware Constraints:**

  - AI Deck 1.1 (GAP8)
  - Camera: 160x120 Greyscale
  - Compute Limit: Quantized models only (int8)

### **Your Implementation Tasks**

#### **Task 1: Long-Range Target Acquisition**

```python
"""
File: src/perception/long_range_detector.py

Implement detection logic optimized for smaller objects:

Classes needed:

1. LongRangeDetector:
   - load_model_v2_corner() -> Quantized Model
   - preprocess_zoom(image) -> cropped_image
   
   Logic:
   - The target will appear smaller (fewer pixels) during the approach.
   - Strategy: Implement a "Digital Zoom" or Region of Interest (ROI) scanning if detection fails on the full frame.
   - Confidence Threshold: Lower initial threshold (e.g., 0.5) to detect "candidates", then verify with multi-frame tracking.
   
   GAP8 Optimization:
   - Use a model trained on "small object" dataset (drones at 4-5m distance).
   - Output: Bounding Box + Distance Estimate.
"""
```

#### **Task 2: Background Clutter Rejection**

```python
"""
File: src/perception/clutter_filter.py

Implement logic to distinguish the drone from the cage wall/corner:

Classes needed:

1. ClutterRejection:
   - Methods:
     - check_stationarity(bbox_history)
     - filter_linear_structures(image, bbox) 
     
   Logic:
   - The cage mesh creates strong linear features (lines). The drone is "blob-like".
   - If a detection overlaps significantly with vertical/horizontal lines extending beyond the box, discard it (likely a pole).
   - Use optical flow or frame differencing: The target is static, but as the camera moves, the parallax of the target vs. the wall (background) might differ slightly.
   - **Critical:** Reject detections that are geometrically impossible (e.g., detecting a target "inside" the wall margin if coupled with odometry).
"""
```

#### **Task 3: Visual Servoing for Corner Approach**

```python
"""
File: src/perception/visual_servo.py

Provide real-time error corrections for the flight controller:

Classes needed:

1. PrecisionGuidance:
   - Methods:
     - calculate_centering_error(bbox, image_center) -> (err_x, err_y)
     - estimate_distance_to_impact(bbox_width) -> float
     
   Logic:
   - As the drone approaches the corner, OptiTrack might be jittery or occluded by the mesh.
   - The Vision System becomes the primary source of truth for X/Y alignment relative to the target.
   - Output: `visual_error_norm` (normalized -1 to 1).
   - Update Rate: Maximize to 30Hz+ during "PRECISION_APPROACH" phase.
"""
```

#### **Task 4: Power & State Management**

```python
"""
File: src/perception/vision_state_manager.py

Manage the AI Deck resources to save battery/bandwidth:

Classes needed:

1. VisionLifecycle:
   - Methods:
     - set_mode(mode: Enum)
       - IDLE: Camera off.
       - LONG_RANGE: High exposure, full FOV.
       - TERMINAL: Low exposure (prevent washout from LEDs), ROI processing.
       
   Logic:
   - Scenario 2 requires a long flight to the corner.
   - Disable Neural Net inference during the initial transit (X < 5.0m) to save power? (Optional, but good for "Battery Optimized" theme).
   - Or, switch models: Use a lightweight motion detector during transit, switch to CNN for final identification.
"""
```

### **Algorithm Requirements**

#### **Distance Estimation via Pinhole Model**

```python
def estimate_precise_distance(bbox_width_px):
    """
    Critical for stopping before the wall.
    d = (real_width_mm * focal_length_px) / width_px
    """
    REAL_WIDTH_MM = 92.0
    FOCAL_LENGTH_PX = 120.0 # Calibrate this!
    
    dist_mm = (REAL_WIDTH_MM * FOCAL_LENGTH_PX) / bbox_width_px
    return dist_mm / 1000.0 # meters
```

#### **Visual Servoing Error**

```python
def calculate_yaw_correction(bbox_center_x, image_width=160):
    """
    Returns a value from -1.0 (Rotate Left) to 1.0 (Rotate Right)
    to keep the target perfectly centered during approach.
    """
    center_x = image_width / 2.0
    error = (bbox_center_x - center_x) / center_x
    return error
```

### **Integration Requirements**

  - **Input:** Receive `mission_phase` from Agent 4 (Mission Coord).
      - Trigger "LONG\_RANGE" mode when X \> 3.0m.
      - Trigger "TERMINAL" mode when X \> 8.0m.
  - **Output:** Publish `target_relative_coords` (x, y, z) to Agent 1 (Controller).
  - **Safety:** If vision loses target for \> 0.5s during `PRECISION_APPROACH`, send `HOVER_IMMEDIATE` flag.

### **Success Criteria**

  - âœ… **Early Detection:** Target identified at \>3m distance.
  - âœ… **Wall Rejection:** No false positives from the cage mesh pattern.
  - âœ… **Stop Distance:** Visual distance estimation triggers the "STOP" command at exactly 0.5m from the target (keeping the drone safe from the wall).
  - âœ… **Framerate:** Maintenance of \>30 FPS during the terminal phase for smooth control.

**Start with Task 1 (Long Range Detector)**. Fine-tuning the model to detect the Crazyflie from 4+ meters on a 160px wide image is the hardest vision challenge here. You may need to implement a "scanning window" approach.